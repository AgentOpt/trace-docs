---
title: Documentation
description: Complete guide to building self-optimizing AI systems with Trace2
---

# Trace2 Documentation

Welcome to the Trace2 documentation! Trace2 is a PyTorch-like library for training AI agents end-to-end using general feedback.

## Quick Links

<Cards>
  <Card title="Installation" href="/docs/getting-started/installation" icon="download" />
  <Card title="Quick Start" href="/docs/getting-started/quick-start" icon="zap" />
  <Card title="Core Concepts" href="/docs/core-concepts" icon="book" />
  <Card title="API Reference" href="/docs/api-reference" icon="code" />
</Cards>

## What is Trace2?

Trace2 is a new AutoDiff-like tool for training AI systems with:

- ðŸŽ¯ **General Feedback**: Use rewards, natural language, test results, or any feedback
- ðŸ“Š **Computation Graphs**: Automatic tracing of execution like PyTorch
- ðŸ”§ **Real Python Code**: Write actual functions, not strings
- âš¡ **Multiple Optimizers**: Choose between OptoPrime, OPRO, and TextGrad
- ðŸ¤– **LLM Agnostic**: Works with OpenAI, Anthropic, and 100+ providers

## Getting Started

```bash
pip install trace-opt
```

Then write your first optimizable function:

```python
from opto.trace import bundle
from opto.optimizers import OptoPrime

@bundle(trainable=True)
def my_function(input):
    """This function will be optimized."""
    return input

optimizer = OptoPrime(my_function.parameters())
```

## Documentation Structure

### ðŸ“š Getting Started
Start here if you're new to Trace2. Learn installation, basic concepts, and configuration.

[â†’ Get Started](/docs/getting-started/installation)

### ðŸ§  Core Concepts
Deep dive into computation graphs, nodes, bundles, and feedback functions.

[â†’ Learn Concepts](/docs/core-concepts)

### ðŸš€ Optimizers
Compare and learn about OptoPrime, OPRO, and TextGrad optimizers.

[â†’ Choose Optimizer](/docs/optimizers)

### ðŸ“– Guides
Best practices, LLM backends, debugging, and production tips.

[â†’ Read Guides](/docs/guides)

### ðŸ’¡ Examples
Hands-on examples from code optimization to multi-agent systems.

[â†’ See Examples](/docs/examples)

### ðŸŽ“ Tutorials
Step-by-step tutorials converted from Jupyter notebooks.

[â†’ Start Tutorial](/docs/tutorials)

### ðŸ“˜ API Reference
Complete Python API documentation auto-generated from source.

[â†’ API Docs](/docs/api-reference)

## Community

- [GitHub](https://github.com/AgentOpt/OpenTrace) - Source code and issues
- [Discord](https://discord.gg/4VeAvwFcWy) - Community chat
- [Paper](https://arxiv.org/abs/2406.16218) - NeurIPS 2024
- [Roadmap](https://docs.google.com/spreadsheets/d/1dMoECd2Soj6bATpkNDeaMxl0ymOYCtGq7ZiHr0JRdJU/edit?usp=sharing) - Future plans

## Citation

If you use Trace2 in your research, please cite:

```bibtex
@article{cheng2024trace,
  title={Trace is the Next AutoDiff: Generative Optimization with Rich Feedback, Execution Traces, and LLMs},
  author={Cheng, Ching-An and Nie, Allen and Swaminathan, Adith},
  journal={arXiv preprint arXiv:2406.16218},
  year={2024}
}
```
